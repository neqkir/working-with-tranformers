{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled3.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOseFWpRiiVjpSaqjEUY7kw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/neqkir/working-with-tranformers/blob/main/BERT/bertsumabs-text-summarization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "QUICK_RUN = True"
      ],
      "metadata": {
        "id": "gqJpyscX9IqI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wDIqBilErXYC"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade \n",
        "!pip install -q git+https://github.com/microsoft/nlp-recipes.git\n",
        "!pip install transformers\n",
        "!pip install eval\n",
        "!pip install rouge\n",
        "!pip install jsonlines\n",
        "!pip install pyrouge\n",
        "!pip install scrapbook\n",
        "!pip install indicnlp\n",
        "#!pip install indicnlp.tokenize\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "import sys\n",
        "from tempfile import TemporaryDirectory\n",
        "import torch\n",
        "import nltk\n",
        "from nltk import tokenize\n",
        "import pandas as pd\n",
        "import pprint\n",
        "import scrapbook as sb\n",
        "\n",
        "nlp_path = os.path.abspath(\"../../\")\n",
        "if nlp_path not in sys.path:\n",
        "    sys.path.insert(0, nlp_path)\n",
        "\n",
        "from utils_nlp import models\n",
        "from utils_nlp.models import transformers \n",
        "from utils_nlp.models.transformers.datasets import SummarizationDataset\n",
        "from utils_nlp import eval\n",
        "from utils_nlp.eval import rouge\n",
        "from utils_nlp.dataset.cnndm import CNNDMSummarizationDataset\n",
        "from utils_nlp.eval import compute_rouge_python\n",
        "\n",
        "from utils_nlp.models.transformers.abstractive_summarization_bertsum \\\n",
        "     import BertSumAbs, BertSumAbsProcessor"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset we used for this notebook is CNN/DM dataset which contains the documents and accompanying questions from the news articles of CNN and Daily mail. The highlights in each article are used as summary. The dataset consits of ~289K training examples, ~11K valiation examples and ~11K test examples. The length of the news articles is 781 tokens on average and the summaries are of 3.75 sentences and 56 tokens on average."
      ],
      "metadata": {
        "id": "1leWQsmC9oxI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# the data path used to save the downloaded data file\n",
        "DATA_PATH = TemporaryDirectory().name\n",
        "# The number of lines at the head of data file used for preprocessing. -1 means all the lines.\n",
        "TOP_N = 100\n",
        "if not QUICK_RUN:\n",
        "    TOP_N = -1\n",
        "\n",
        "train_dataset, test_dataset = CNNDMSummarizationDataset(\n",
        "    top_n=TOP_N, local_cache_path=DATA_PATH, prepare_extractive=False\n",
        ")"
      ],
      "metadata": {
        "id": "k6DDOzdB5Jbe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model finetuning"
      ],
      "metadata": {
        "id": "KVKLCN4x5001"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# notebook parameters\n",
        "# the cache path\n",
        "CACHE_PATH = TemporaryDirectory().name\n",
        "\n",
        "# model parameters\n",
        "MODEL_NAME = \"bert-base-uncased\"\n",
        "MAX_POS = 768\n",
        "MAX_SOURCE_SEQ_LENGTH = 640\n",
        "MAX_TARGET_SEQ_LENGTH = 140\n",
        "\n",
        "# mixed precision setting. To enable mixed precision training, follow instructions in SETUP.md.\n",
        "FP16 = False\n",
        "if FP16:\n",
        "    FP16_OPT_LEVEL = \"O2\"\n",
        "\n",
        "# fine-tuning parameters\n",
        "# batch size, unit is the number of tokens\n",
        "BATCH_SIZE_PER_GPU = 1\n",
        "\n",
        "\n",
        "# GPU used for training\n",
        "NUM_GPUS = torch.cuda.device_count()\n",
        "if NUM_GPUS > 0:\n",
        "    BATCH_SIZE = NUM_GPUS * BATCH_SIZE_PER_GPU\n",
        "else:\n",
        "    BATCH_SIZE = 1\n",
        "\n",
        "\n",
        "# Learning rate\n",
        "LEARNING_RATE_BERT = 5e-4 / 2.0\n",
        "LEARNING_RATE_DEC = 0.05 / 2.0\n",
        "\n",
        "\n",
        "# How often the statistics reports show up in training, unit is step.\n",
        "REPORT_EVERY = 10\n",
        "SAVE_EVERY = 500\n",
        "\n",
        "# total number of steps for training\n",
        "MAX_STEPS = 1e3\n",
        "\n",
        "if not QUICK_RUN:\n",
        "    MAX_STEPS = 5e3\n",
        "\n",
        "WARMUP_STEPS_BERT = 2000\n",
        "WARMUP_STEPS_DEC = 1000"
      ],
      "metadata": {
        "id": "2lAg5-Mf54vQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# processor which contains the colloate function to load the preprocessed data\n",
        "processor = BertSumAbsProcessor(cache_dir=CACHE_PATH, max_src_len=MAX_SOURCE_SEQ_LENGTH, max_tgt_len=MAX_TARGET_SEQ_LENGTH)\n",
        "# summarizer\n",
        "summarizer = BertSumAbs(\n",
        "    processor, cache_dir=CACHE_PATH, max_pos_length=MAX_POS\n",
        ")"
      ],
      "metadata": {
        "id": "rDJTu9WG6g7L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE_PER_GPU*NUM_GPUS"
      ],
      "metadata": {
        "id": "afT_48Zn6kFN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summarizer.fit(\n",
        "    train_dataset,\n",
        "    num_gpus=NUM_GPUS,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    max_steps=MAX_STEPS,\n",
        "    learning_rate_bert=LEARNING_RATE_BERT,\n",
        "    learning_rate_dec=LEARNING_RATE_DEC,\n",
        "    warmup_steps_bert=WARMUP_STEPS_BERT,\n",
        "    warmup_steps_dec=WARMUP_STEPS_DEC,\n",
        "    save_every=SAVE_EVERY,\n",
        "    report_every=REPORT_EVERY * 5,\n",
        "    fp16=FP16,\n",
        "    # checkpoint=\"saved checkpoint path\"\n",
        ")"
      ],
      "metadata": {
        "id": "oEG6Gh0e6mqL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summarizer.save_model(MAX_STEPS, os.path.join(CACHE_PATH, \"bertsumabs.pt\"))"
      ],
      "metadata": {
        "id": "xIYMnxvG88GD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Evaluation\n",
        "\n",
        "To run rouge evaluation, please refer to the section of compute_rouge_perl in summarization_evaluation.ipynb for setup. For the settings in this notebook with QUICK_RUN=False, you should get ROUGE scores close to the following numbers:\n",
        "```\n",
        "{'rouge-1': {'f': 0.34819639878321873, 'p': 0.39977932634737307, \n",
        "'r': 0.34429079596863604}, \n",
        "'rouge-2': {'f': 0.13919271352557894, 'p': 0.16129965067780644, \n",
        "'r': 0.1372938054050938}, \n",
        "'rouge-l': {'f': 0.2313282318854973, 'p': 0.26664667422849747, \n",
        "'r': 0.22850294283399628}}\n",
        "```\n",
        "Better performance can be achieved by increasing the MAX_STEPS."
      ],
      "metadata": {
        "id": "tVhZkrXF9F6G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TEST_TOP_N = 32\n",
        "if not QUICK_RUN:\n",
        "    TEST_TOP_N = len(test_dataset)\n",
        "\n",
        "if NUM_GPUS:\n",
        "    BATCH_SIZE = NUM_GPUS * BATCH_SIZE_PER_GPU\n",
        "else:\n",
        "    BATCH_SIZE = 1\n",
        "    \n",
        "shortened_dataset = test_dataset.shorten(top_n=TEST_TOP_N)\n",
        "src = shortened_dataset.get_source()\n",
        "reference_summaries = [\" \".join(t).rstrip(\"\\n\") for t in shortened_dataset.get_target()]\n",
        "generated_summaries = summarizer.predict(\n",
        "    shortened_dataset, batch_size=BATCH_SIZE, num_gpus=NUM_GPUS\n",
        ")\n",
        "assert len(generated_summaries) == len(reference_summaries)"
      ],
      "metadata": {
        "id": "ZGpkz4vW9cbb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "src[0]"
      ],
      "metadata": {
        "id": "V998G9xW9iwk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generated_summaries[0]"
      ],
      "metadata": {
        "id": "0WL-w9kw9k_p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reference_summaries[0]"
      ],
      "metadata": {
        "id": "_SYwcpcT9mPF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rouge_scores = compute_rouge_python(cand=generated_summaries, ref=reference_summaries)\n",
        "pprint.pprint(rouge_scores)"
      ],
      "metadata": {
        "id": "0arQTZO-9oBl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for testing\n",
        "sb.glue(\"rouge_2_f_score\", rouge_scores['rouge-2']['f'])"
      ],
      "metadata": {
        "id": "GrtuPya29p6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example"
      ],
      "metadata": {
        "id": "E73glRQ99tDg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "source = \"\"\"\n",
        "But under the new rule, set to be announced in the next 48 hours, Border Patrol agents would immediately return anyone to Mexico — without any detainment and without any due process — who attempts to cross the southwestern border between the legal ports of entry. The person would not be held for any length of time in an American facility.\n",
        "\n",
        "Although they advised that details could change before the announcement, administration officials said the measure was needed to avert what they fear could be a systemwide outbreak of the coronavirus inside detention facilities along the border. Such an outbreak could spread quickly through the immigrant population and could infect large numbers of Border Patrol agents, leaving the southwestern border defenses weakened, the officials argued.\n",
        "The Trump administration plans to immediately turn back all asylum seekers and other foreigners attempting to enter the United States from Mexico illegally, saying the nation cannot risk allowing the coronavirus to spread through detention facilities and Border Patrol agents, four administration officials said.\n",
        "The administration officials said the ports of entry would remain open to American citizens, green-card holders and foreigners with proper documentation. Some foreigners would be blocked, including Europeans currently subject to earlier travel restrictions imposed by the administration. The points of entry will also be open to commercial traffic.\"\"\""
      ],
      "metadata": {
        "id": "5CbAflwJ9uIO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = SummarizationDataset(\n",
        "    None, source=[source], source_preprocessing=[tokenize.sent_tokenize],\n",
        ")\n",
        "generated_summaries = summarizer.predict(test_dataset, batch_size=1, num_gpus=NUM_GPUS)"
      ],
      "metadata": {
        "id": "1iq7n7d89v_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generated_summaries[0]"
      ],
      "metadata": {
        "id": "vFOUg02K9xJa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if os.path.exists(DATA_PATH):\n",
        "    shutil.rmtree(DATA_PATH, ignore_errors=True)\n",
        "if os.path.exists(CACHE_PATH):\n",
        "    shutil.rmtree(CACHE_PATH, ignore_errors=True)"
      ],
      "metadata": {
        "id": "g9jzOWe690cD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}